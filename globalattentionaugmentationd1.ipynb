{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense,GlobalMaxPooling2D,Add,Reshape,BatchNormalization,Activation\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.backend import function\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.layers import Input, Multiply\nfrom tensorflow.keras.applications import InceptionV3,MobileNet,DenseNet201","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-03T04:56:34.746427Z","iopub.execute_input":"2023-10-03T04:56:34.746762Z","iopub.status.idle":"2023-10-03T04:56:34.753399Z","shell.execute_reply.started":"2023-10-03T04:56:34.746734Z","shell.execute_reply":"2023-10-03T04:56:34.752427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set a random seed for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:54:07.638399Z","iopub.execute_input":"2023-10-03T04:54:07.638722Z","iopub.status.idle":"2023-10-03T04:54:07.642948Z","shell.execute_reply.started":"2023-10-03T04:54:07.638693Z","shell.execute_reply":"2023-10-03T04:54:07.641936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def attention_module(input,ratio=8):\n    channel = input.shape[-1]\n    avg_pool = GlobalAveragePooling2D()(input)\n    max_pool = GlobalMaxPooling2D()(input)\n\n    channel_avg = Dense(units=channel // ratio, activation='relu',kernel_initializer='he_normal',use_bias=True)(avg_pool)\n    channel_max = Dense(units=channel // ratio, activation='relu',kernel_initializer='he_normal',use_bias=True)(max_pool)\n\n    channel_avg = Dense(units=channel, activation='sigmoid')(channel_avg)\n    channel_max = Dense(units=channel, activation='sigmoid')(channel_max)\n\n    channel_attention = Add()([channel_avg, channel_max])\n    channel_attention = Multiply()([input, Reshape((1, 1, channel))(channel_attention)])\n\n    return channel_attention\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:55:27.181327Z","iopub.execute_input":"2023-10-03T04:55:27.181672Z","iopub.status.idle":"2023-10-03T04:55:27.188120Z","shell.execute_reply.started":"2023-10-03T04:55:27.181644Z","shell.execute_reply":"2023-10-03T04:55:27.187202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def spatial_attention(input):\n    kernel_size = 7\n    \n    avg_pool = tf.reduce_mean(input, axis=-1)\n    avg_pool=tf.expand.dim(avg_pool,axis=-1)\n    \n    max_pool = tf.reduce_max(input, axis=-1)\n    max_pool=tf.expand_dims(max_pool,axis=-1)\n    \n    concat_tensor = Concatenate()[avg_pool, max_pool]\n    \n    attention = Conv2D(filters=1, kernel_size=kernel_size,padding='same', activation='sigmoid')(concat_tensor)\n    \n    return Multiply()([input_tensor, attention])","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:54:30.046725Z","iopub.execute_input":"2023-10-03T04:54:30.047059Z","iopub.status.idle":"2023-10-03T04:54:30.052596Z","shell.execute_reply.started":"2023-10-03T04:54:30.047032Z","shell.execute_reply":"2023-10-03T04:54:30.051671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_Global_attention_augmented_mobilenet(input_shape, num_classes,attention=False):\n    # Load MobileNet base model without top layer\n    base_model = MobileNet(include_top=False, weights='imagenet', input_shape=input_shape)\n    base_model.trainable = False\n\n    # Attention augmented MobileNet architecture\n    input_tensor = Input(shape=input_shape)\n    x = base_model(input_tensor)\n\n    # Apply attention module\n    if(attention):\n        x = attention_module(x)\n        # Additional Convolutional layers after attention mechanisms\n        x = Conv2D(128, (3, 3), padding='same')(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n\n    # Add classification layers\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    output_tensor = Dense(num_classes, activation='softmax')(x)\n\n    # Create the model\n    model = Model(inputs=input_tensor, outputs=output_tensor)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:54:31.655795Z","iopub.execute_input":"2023-10-03T04:54:31.656446Z","iopub.status.idle":"2023-10-03T04:54:31.662583Z","shell.execute_reply.started":"2023-10-03T04:54:31.656417Z","shell.execute_reply":"2023-10-03T04:54:31.661633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_Global_InceptionV3_model(input_shape, num_classes,attention=False):\n    \n    # Load Inception-v3 base model without top layer\n    base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape)\n    base_model.trainable = False\n\n    # Attention augmented Inception-v3 architecture\n    input_tensor = Input(shape=input_shape)\n    x = base_model(input_tensor)\n\n    # Apply attention module\n    if(attention):\n        x = attention_module(x)\n        # Additional Convolutional layers after attention mechanisms\n        x = Conv2D(128, (3, 3), padding='same')(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n\n    # Add classification layers\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    output_tensor = Dense(num_classes, activation='softmax')(x)\n\n    # Create the model\n    model = Model(inputs=input_tensor, outputs=output_tensor)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T06:06:01.289086Z","iopub.execute_input":"2023-10-03T06:06:01.289404Z","iopub.status.idle":"2023-10-03T06:06:01.296918Z","shell.execute_reply.started":"2023-10-03T06:06:01.289375Z","shell.execute_reply":"2023-10-03T06:06:01.295943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report, balanced_accuracy_score, average_precision_score, confusion_matrix\n\ndef evaluate_classification(y_true, y_pred, average='macro'):\n    \"\"\"\n    Evaluate the classification performance and calculate micro-average, balanced accuracy, and average precision.\n\n    Parameters:\n        y_true (numpy array or list): True labels.\n        y_pred (numpy array or list): Predicted labels.\n        average (str, optional): The averaging strategy to use for average precision.\n                                 Possible values are 'macro', 'micro', 'weighted', and None.\n                                 Default is 'macro'.\n\n    Returns:\n        report (str): The classification report as a string.\n        balanced_acc (float): The balanced accuracy.\n        avg_precision (float): The average precision.\n        micro_avg_precision (float): The micro-average precision.\n        micro_avg_recall (float): The micro-average recall.\n        micro_avg_f1_score (float): The micro-average F1-score.\n    \"\"\"\n    report = classification_report(y_true, y_pred, output_dict=True, zero_division=1)\n    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n    avg_precision = average_precision_score(y_true, y_pred, average=average)\n\n    # Calculate micro-average precision and recall using confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    tp_sum = np.sum(np.diag(cm))\n    pred_sum = np.sum(cm, axis=0)\n    true_sum = np.sum(cm, axis=1)\n    micro_avg_precision = tp_sum / pred_sum.sum()\n    micro_avg_recall = tp_sum / true_sum.sum()\n    micro_avg_f1_score = 2 * (micro_avg_precision * micro_avg_recall) / (micro_avg_precision + micro_avg_recall)\n\n    return report, balanced_acc, avg_precision, micro_avg_precision, micro_avg_recall, micro_avg_f1_score\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:54:35.333626Z","iopub.execute_input":"2023-10-03T04:54:35.333989Z","iopub.status.idle":"2023-10-03T04:54:35.341582Z","shell.execute_reply.started":"2023-10-03T04:54:35.333959Z","shell.execute_reply":"2023-10-03T04:54:35.340342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Load and split the dataset\ntrain_data_dir = '/kaggle/input/eye-diseases-classification/dataset'\n#validation_data_dir = 'd:/chaman/cataract/test'\ninput_shape = (224, 224)\nbatch_size = 32\nnum_classes=4\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:54:36.491449Z","iopub.execute_input":"2023-10-03T04:54:36.492492Z","iopub.status.idle":"2023-10-03T04:54:36.497450Z","shell.execute_reply.started":"2023-10-03T04:54:36.492426Z","shell.execute_reply":"2023-10-03T04:54:36.496638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Preprocess the images\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2,  # 20% validation split\n)\n\n#validation_datagen = ImageDataGenerator(rescale=1.0/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=input_shape,\n    batch_size=batch_size,\n    class_mode='categorical',  # Updated to 'categorical'\n    subset=\"training\"\n)\n\n\nvalidation_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=input_shape,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'  # Subset for validation data\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:54:38.122406Z","iopub.execute_input":"2023-10-03T04:54:38.122724Z","iopub.status.idle":"2023-10-03T04:54:39.915993Z","shell.execute_reply.started":"2023-10-03T04:54:38.122696Z","shell.execute_reply":"2023-10-03T04:54:39.915135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_counts = train_generator.classes\nclass_indices = train_generator.class_indices\nnum_classes = len(class_indices)\n\n# Create a dictionary to store the counts for each class\nclass_counts_dict = {class_name: np.sum(class_counts == class_idx) for class_name, class_idx in class_indices.items()}\n\n# Print the class counts\nfor class_name, count in class_counts_dict.items():\n    print(f\"Class '{class_name}': {count} samples\")\n\n# Alternatively, you can simply print the 'class_counts_dict' dictionary\nprint(class_counts_dict)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:54:40.147439Z","iopub.execute_input":"2023-10-03T04:54:40.148071Z","iopub.status.idle":"2023-10-03T04:54:40.155338Z","shell.execute_reply.started":"2023-10-03T04:54:40.148039Z","shell.execute_reply":"2023-10-03T04:54:40.154353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nMobileNetModel = create_Global_attention_augmented_mobilenet(input_shape + (3,), num_classes,attention=True)\n\n# 4. Compile the model\nMobileNetModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:56:42.097586Z","iopub.execute_input":"2023-10-03T04:56:42.097940Z","iopub.status.idle":"2023-10-03T04:56:43.212830Z","shell.execute_reply.started":"2023-10-03T04:56:42.097908Z","shell.execute_reply":"2023-10-03T04:56:43.211925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"InceptionV3Model = create_Global_InceptionV3_model(input_shape + (3,), num_classes,attention=True)\n\nInceptionV3Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T06:06:01.298522Z","iopub.execute_input":"2023-10-03T06:06:01.299092Z","iopub.status.idle":"2023-10-03T06:06:03.998107Z","shell.execute_reply.started":"2023-10-03T06:06:01.299059Z","shell.execute_reply":"2023-10-03T06:06:03.997188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=40, verbose=0, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:56:57.590518Z","iopub.execute_input":"2023-10-03T04:56:57.590848Z","iopub.status.idle":"2023-10-03T04:56:57.598517Z","shell.execute_reply.started":"2023-10-03T04:56:57.590817Z","shell.execute_reply":"2023-10-03T04:56:57.597252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. Train the model\nepochs = 100\n\n# Create a directory to save the best model weights during training\nos.makedirs('models', exist_ok=True)\nmodel_checkpoint = ModelCheckpoint('models/best_GlobalmobilnetmodelD1.h5', save_best_only=True, save_weights_only=True)\n\nhistory = MobileNetModel.fit(\n    train_generator,\n    #steps_per_epoch=train_generator.n // train_generator.batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    #validation_steps=validation_generator.n // validation_generator.batch_size,\n    callbacks=[model_checkpoint,early_stopping]\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T04:57:01.805375Z","iopub.execute_input":"2023-10-03T04:57:01.805703Z","iopub.status.idle":"2023-10-03T06:06:01.286968Z","shell.execute_reply.started":"2023-10-03T04:57:01.805676Z","shell.execute_reply":"2023-10-03T06:06:01.285954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a directory to save the best model weights during training\nos.makedirs('models', exist_ok=True)\nmodel_checkpoint = ModelCheckpoint('models/best_GlobalInceptionModelD1.h5', save_best_only=True, save_weights_only=True)\n\nInceptionV3history = InceptionV3Model.fit(\n    train_generator,\n    #steps_per_epoch=train_generator.n // train_generator.batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    #validation_steps=validation_generator.n // validation_generator.batch_size,\n    callbacks=[model_checkpoint]\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T06:06:04.000192Z","iopub.execute_input":"2023-10-03T06:06:04.000761Z","iopub.status.idle":"2023-10-03T08:09:45.508354Z","shell.execute_reply.started":"2023-10-03T06:06:04.000728Z","shell.execute_reply":"2023-10-03T08:09:45.507402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MobileNetModel.save('GAAMD1.h5')\nInceptionV3Model.save('GAAIV3D1.h5')","metadata":{"execution":{"iopub.status.busy":"2023-10-03T08:09:45.510203Z","iopub.execute_input":"2023-10-03T08:09:45.511251Z","iopub.status.idle":"2023-10-03T08:09:46.336641Z","shell.execute_reply.started":"2023-10-03T08:09:45.511219Z","shell.execute_reply":"2023-10-03T08:09:46.335705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Evaluate the model\nMobileNetEvaluation = MobileNetModel.evaluate(validation_generator)\nprint(\"Validation Accuracy: {:.2f}%\".format(MobileNetEvaluation[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2023-10-03T08:09:46.338009Z","iopub.execute_input":"2023-10-03T08:09:46.339750Z","iopub.status.idle":"2023-10-03T08:09:57.022935Z","shell.execute_reply.started":"2023-10-03T08:09:46.339717Z","shell.execute_reply":"2023-10-03T08:09:57.022061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Evaluate the model\nInceptionV3Evaluation = InceptionV3Model.evaluate(validation_generator)\nprint(\"Validation Accuracy: {:.2f}%\".format(InceptionV3Evaluation[1] * 100))","metadata":{"execution":{"iopub.status.busy":"2023-10-03T08:09:57.025181Z","iopub.execute_input":"2023-10-03T08:09:57.025722Z","iopub.status.idle":"2023-10-03T08:10:17.904927Z","shell.execute_reply.started":"2023-10-03T08:09:57.025690Z","shell.execute_reply":"2023-10-03T08:10:17.903943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_Global_attention_augmented_Densenet201_model(input_shape, num_classes,attention=False):\n    \n    # Load Inception-v3 base model without top layer\n    base_model = DenseNet201(include_top=False, weights='imagenet', input_shape=input_shape)\n    base_model.trainable = False\n\n    # Attention augmented Inception-v3 architecture\n    input_tensor = Input(shape=input_shape)\n    x = base_model(input_tensor)\n\n    # Apply attention module\n    if(attention):\n        x=attention_module(x)\n        # Additional Convolutional layers after attention mechanisms\n        x = Conv2D(128, (3, 3), padding='same')(x)\n        x = BatchNormalization()(x)\n        x = Activation('relu')(x)\n\n    #x = channel_attention(x,16)\n\n    # Add classification layers\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(1024, activation='relu')(x)\n    output_tensor = Dense(num_classes, activation='softmax')(x)\n\n    # Create the model\n    model = Model(inputs=input_tensor, outputs=output_tensor)\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T08:47:26.222495Z","iopub.execute_input":"2023-10-03T08:47:26.222817Z","iopub.status.idle":"2023-10-03T08:47:26.228793Z","shell.execute_reply.started":"2023-10-03T08:47:26.222789Z","shell.execute_reply":"2023-10-03T08:47:26.227910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nDenseNetModel = create_Global_attention_augmented_Densenet201_model(input_shape + (3,), num_classes,attention=True)\n\n# 4. Compile the model\nDenseNetModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T08:47:27.568741Z","iopub.execute_input":"2023-10-03T08:47:27.569891Z","iopub.status.idle":"2023-10-03T08:47:33.845458Z","shell.execute_reply.started":"2023-10-03T08:47:27.569818Z","shell.execute_reply":"2023-10-03T08:47:33.844466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. Train the model\nepochs = 100\n\n# Create a directory to save the best model weights during training\nos.makedirs('models', exist_ok=True)\nmodel_checkpoint = ModelCheckpoint('models/best_GlobalDenseNetmodelD1.h5', save_best_only=True, save_weights_only=True)\n\nhistory = DenseNetModel.fit(\n    train_generator,\n    #steps_per_epoch=train_generator.n // train_generator.batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    #validation_steps=validation_generator.n // validation_generator.batch_size,\n    callbacks=[model_checkpoint,early_stopping]\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-03T08:47:36.366232Z","iopub.execute_input":"2023-10-03T08:47:36.367344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. Evaluate the model\nDenseNetEvaluation = DenseNetModel.evaluate(validation_generator)\nprint(\"Validation Accuracy: {:.2f}%\".format(DenseNetEvaluation[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}